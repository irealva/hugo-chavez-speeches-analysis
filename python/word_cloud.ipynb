{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import nltk\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/ire/nltk_data',\n",
       " '/usr/share/nltk_data',\n",
       " '/usr/local/share/nltk_data',\n",
       " '/usr/lib/nltk_data',\n",
       " '/usr/local/lib/nltk_data']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.data.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filelist = !ls ../data/original/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/original/1999.0001.txt',\n",
       " '../data/original/1999.0002.txt',\n",
       " '../data/original/1999.0003.txt',\n",
       " '../data/original/2000.0001.txt',\n",
       " '../data/original/2000.0002.txt',\n",
       " '../data/original/2000.0003.txt',\n",
       " '../data/original/2000.0004.txt',\n",
       " '../data/original/2001.0001.txt',\n",
       " '../data/original/2001.0002.txt',\n",
       " '../data/original/2001.0003.txt',\n",
       " '../data/original/2001.0004.txt',\n",
       " '../data/original/2001.0005.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "speeches = []\n",
    "for filen in filelist:\n",
    "    with open(filen) as handle:\n",
    "        speeches.append(handle.read()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(speeches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Accents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "\n",
    "#Note: this also removes the Ã±, not just accents\n",
    "def strip_accents(s):\n",
    "   return ''.join(c for c in unicodedata.normalize('NFD', unicode(s, 'utf8'))\n",
    "                  if unicodedata.category(c) != 'Mn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Accents - one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test = strip_accents(speeches[0])\n",
    "\n",
    "# newpath = '../data/noaccent/'\n",
    "# filename = newpath + 'testfile.txt'\n",
    "# file = open(filename,\"w\")\n",
    "\n",
    "# file.write(test.encode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Accents - multiple files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "speechnames = [filen.split('/')[3] for filen in filelist]\n",
    "# print(speechnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "newpath = '../data/noaccent/'\n",
    "\n",
    "for i, speech in enumerate(speeches):\n",
    "    text_without_accents = strip_accents(speech)\n",
    "    filename = newpath + speechnames[i] #creating a new path for the file\n",
    "    file = open(filename,\"w\")\n",
    "    file.write(text_without_accents.encode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:textvis]",
   "language": "python",
   "name": "conda-env-textvis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
